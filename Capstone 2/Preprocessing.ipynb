{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to create dataframes\n",
    "Pull only the data to be used by the model with appropriate naming conventions. \n",
    "\n",
    "Includes engineered feature *differential*: $C_d - O_d$  (*daily close - daily open*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(x):\n",
    "    return datetime.strptime(x, '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_data(name, filename):\n",
    "    \"\"\"\n",
    "    function to pull only the data to be used by the model from the flat files\n",
    "    \n",
    "    name is a string used to add the company name to the columns\n",
    "    \n",
    "    filename is a string which must match the name of the flat file in the raw data folder\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv('raw data/'+filename+'.csv', parse_dates =  {'date' : [0]}, \n",
    "                     date_parser = parser)\n",
    "    \n",
    "    df.drop(['2. high', '3. low', '7. dividend amount', '8. split coefficient'],\n",
    "           axis = 1, inplace = True)\n",
    "    df['1. open'] = df['4. close'] - df['1. open'] #create differential values in open column location\n",
    "    df.rename(index = str, columns = {'1. open': name + ' differential',\n",
    "                                      '5. adjusted close': name + ' adj close',\n",
    "                                      '6. volume': name + ' vol'}, inplace = True) \n",
    "    df.drop('4. close', axis = 1, inplace = True) #drop close column\n",
    "    \n",
    "    df.set_index('date', inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_data(name, filename):\n",
    "    \"\"\"\n",
    "    function to pull only the data to be used by the model from the flat files\n",
    "    \n",
    "    name is a string used to add the index name to the columns\n",
    "    \n",
    "    filename is a string which must match the name of the flat file in the raw data folder\n",
    "    \"\"\"\n",
    "        \n",
    "    df = pd.read_csv('raw data/'+filename+'.csv', parse_dates =  {'date' : [0]}, \n",
    "                     date_parser = parser)\n",
    "\n",
    "    df.drop(['High', 'Low'], axis = 1, inplace = True)\n",
    "    df['Open'] = df['Close'] - df['Open'] #create differential values in open column location\n",
    "    df.rename(index = str, columns = {'Open': name + ' differential',\n",
    "                                      'Adj Close': name + ' adj close',\n",
    "                                      'Volume': name + ' vol'}, inplace = True) \n",
    "    df.drop('Close', axis = 1, inplace = True) #drop close column\n",
    "    \n",
    "    df.set_index('date', inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from flat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historical stock data\n",
    "amzn = get_company_data('amzn', 'amzn')\n",
    "aapl = get_company_data('aapl', 'apple')\n",
    "googl = get_company_data('googl', 'google')\n",
    "msft = get_company_data('msft', 'msft')\n",
    "#technical indicators\n",
    "ma7 = pd.read_csv('raw data/msft_ma7.csv', parse_dates =  {'date' : [0]}, \n",
    "                  date_parser = parser)\n",
    "ma7.set_index('date', inplace = True)  # set DateTimeIndex\n",
    "ma21 = pd.read_csv('raw data/msft_ma21.csv', parse_dates =  {'date' : [0]}, \n",
    "                   date_parser = parser)\n",
    "ma21.set_index('date', inplace = True)  # set DateTimeIndex\n",
    "bbands = pd.read_csv('raw data/msft_bbands.csv', parse_dates =  {'date' : [0]}, \n",
    "                     date_parser = parser)\n",
    "bbands.set_index('date', inplace = True)  # set DateTimeIndex\n",
    "macd = pd.read_csv('raw data/msft_macd.csv', parse_dates =  {'date' : [0]}, \n",
    "                   date_parser = parser)\n",
    "macd.set_index('date', inplace = True)  # set DateTimeIndex\n",
    "#indicies\n",
    "nasdaq = get_index_data('nasdaq', '^IXIC')\n",
    "nyse = get_index_data('nyse', '^NYA')\n",
    "sp500 = get_index_data('sp500', '^GSPC')\n",
    "tb13 = get_index_data('tb13', '^IRX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Fourier Transforms\n",
    "to denoise the data and add long- and short-term trends.\n",
    "\n",
    "3 component transforms are long term trends, 9 component are short term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add fourier transforms with 3, 6, and 9 components\n",
    "close_fft = np.fft.fft(np.asarray(msft['msft adj close'].tolist()))\n",
    "fft_df = pd.DataFrame({'fft':close_fft})\n",
    "fft_list = np.asarray(fft_df['fft'].tolist())\n",
    "for num_ in [3, 6, 9]:\n",
    "    fft_list_m10= np.copy(fft_list); fft_list_m10[num_:-num_]=0\n",
    "    fft_df['fft {}'.format(num_)] = np.fft.ifft(fft_list_m10)\n",
    "fft_df.drop(['fft'], axis = 1, inplace = True)\n",
    "fft_df = fft_df.set_index(amzn.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create predictors and target dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = pd.DataFrame(index = amzn.index)  # blank dataframe to merge data into\n",
    "\n",
    "df_to_merge = [amzn, aapl, googl, msft, ma7, ma21, bbands, macd,  # list of data frames to merge\n",
    "                              nasdaq, nyse, sp500, tb13, fft_df] \n",
    "\n",
    "#merge data into 1 dataframe\n",
    "predictors = pd.concat(df_to_merge, join = 'outer', axis = 1, sort = True) \n",
    "\n",
    "#predictors.dropna(inplace = True)  # drop NaN values\n",
    "\n",
    "#drop target and other unnecessary data from predictors dataframe\n",
    "predictors.drop(['msft adj close', 'Real Middle Band', 'MACD_Hist', 'MACD_Signal'], \n",
    "                axis = 1, inplace = True) \n",
    "\n",
    "target = msft['msft adj close'].copy()  # create target dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push predictors & target sets to flat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors.to_csv('processed data/predictors.csv')\n",
    "target.to_csv('processed data/target.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Testing & Training Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing data is 2016 - 2018, training data is 2010 - 2015\n",
    "predictors_train = predictors.iloc[0:-501]\n",
    "predictors_test = predictors.iloc[-501:]\n",
    "target_train = target.iloc[0:-501]\n",
    "target_test = target.iloc[-501:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_train.to_csv('processed data/predictors_train.csv')\n",
    "predictors_test.to_csv('processed data/predictors_test.csv')\n",
    "target_train.to_csv('processed data/target_train.csv')\n",
    "target_test.to_csv('processed data/target_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
